{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy exploration of MAgents-Battlefield on different topologies\n",
    "## Marc Vicuna, 101214652\n",
    "## Implementation used for tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-step training\n",
    "We first go through the algorithm step-by-step, with commented code to allow an understanding of what is being done.\n",
    "We initialize the environment, train the model and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "#from pettingzoo.magent import battlefield_v3\n",
    "import battlefield_vicuna\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3 import PPO\n",
    "import supersuit as ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel version, death is possibly dangerous.\n",
    "policy_name = \"policy_test\"\n",
    "#Initial environment\n",
    "env = battlefield_vicuna.parallel_env(map_size=46, minimap_mode=False, step_reward=0.005,\n",
    "dead_penalty=-0.1, attack_penalty=-0.1, attack_opponent_reward=0.2,\n",
    "max_cycles=2000, wall=5, noise=0, extra_features=False)\n",
    "env.reset()\n",
    "#Stacking frames for movement #FRAMES ARE STACKED\n",
    "env = ss.frame_stack_v1(env, 2)\n",
    "# Handling the death of agents for vectorization\n",
    "env = ss.black_death_v2(env)\n",
    "#Vectorize the environment\n",
    "env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "##vectorize_aec_env_v0(aec_env, num_envs, num_cpus=0)\n",
    "#Start parallel training. n cpus, 2n environments.\n",
    "env = ss.concat_vec_envs_v1(env, 8, num_cpus=4, base_class='stable_baselines3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### May take minutes or hours depending on the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 17035 |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 3     |\n",
      "|    total_timesteps | 65536 |\n",
      "------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 6777       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 131072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03749514 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.3        |\n",
      "|    entropy_loss         | -3.01      |\n",
      "|    explained_variance   | -1.29      |\n",
      "|    learning_rate        | 0.000622   |\n",
      "|    loss                 | -0.316     |\n",
      "|    n_updates            | 5          |\n",
      "|    policy_gradient_loss | -0.0526    |\n",
      "|    value_loss           | 0.0284     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5913        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033905342 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | -0.0505     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.34       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0724     |\n",
      "|    value_loss           | 0.0171      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5398        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029842123 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | -0.0264     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.325      |\n",
      "|    n_updates            | 15          |\n",
      "|    policy_gradient_loss | -0.063      |\n",
      "|    value_loss           | 0.0132      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5206       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02816482 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.3        |\n",
      "|    entropy_loss         | -2.76      |\n",
      "|    explained_variance   | -0.0218    |\n",
      "|    learning_rate        | 0.000622   |\n",
      "|    loss                 | -0.314     |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0575    |\n",
      "|    value_loss           | 0.00949    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 5088      |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 77        |\n",
      "|    total_timesteps      | 393216    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0284308 |\n",
      "|    clip_fraction        | 0.158     |\n",
      "|    clip_range           | 0.3       |\n",
      "|    entropy_loss         | -2.68     |\n",
      "|    explained_variance   | -0.0276   |\n",
      "|    learning_rate        | 0.000622  |\n",
      "|    loss                 | -0.287    |\n",
      "|    n_updates            | 25        |\n",
      "|    policy_gradient_loss | -0.0538   |\n",
      "|    value_loss           | 0.00669   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4992        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027701706 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | -0.0193     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.049      |\n",
      "|    value_loss           | 0.00461     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4876        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026776994 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | -0.0178     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.293      |\n",
      "|    n_updates            | 35          |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    value_loss           | 0.00347     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4820        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027925896 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | -0.0243     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.277      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 0.00259     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4801        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026339531 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.51       |\n",
      "|    explained_variance   | 0.00231     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.271      |\n",
      "|    n_updates            | 45          |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    value_loss           | 0.002       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4770        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028806897 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.48       |\n",
      "|    explained_variance   | 0.0605      |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.278      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 0.00218     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4706        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040806096 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.00043     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.185      |\n",
      "|    n_updates            | 55          |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 8.37        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 4661       |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 182        |\n",
      "|    total_timesteps      | 851968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08537251 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.3        |\n",
      "|    entropy_loss         | -2.78      |\n",
      "|    explained_variance   | 0.00543    |\n",
      "|    learning_rate        | 0.000622   |\n",
      "|    loss                 | -0.101     |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    value_loss           | 17.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4627        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023567801 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | 0.00774     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.233      |\n",
      "|    n_updates            | 65          |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    value_loss           | 13.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4598        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021375246 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | 0.0255      |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.13       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4579        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018671323 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.95       |\n",
      "|    explained_variance   | 0.0477      |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.0517     |\n",
      "|    n_updates            | 75          |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    value_loss           | 9.68        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 4562       |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 244        |\n",
      "|    total_timesteps      | 1114112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02055647 |\n",
      "|    clip_fraction        | 0.0981     |\n",
      "|    clip_range           | 0.3        |\n",
      "|    entropy_loss         | -2.94      |\n",
      "|    explained_variance   | 0.00417    |\n",
      "|    learning_rate        | 0.000622   |\n",
      "|    loss                 | -0.209     |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0213    |\n",
      "|    value_loss           | 12.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4537        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018569592 |\n",
      "|    clip_fraction        | 0.0742      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | 3.53        |\n",
      "|    n_updates            | 85          |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4526        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016526535 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.0702      |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | 1.49        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4510        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 1310720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015804416 |\n",
      "|    clip_fraction        | 0.0676      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | 0.0765      |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | 0.878       |\n",
      "|    n_updates            | 95          |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4501        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015539978 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | -0.0243     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 10.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4491        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014127229 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | -0.0141     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.0335     |\n",
      "|    n_updates            | 105         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4493         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 335          |\n",
      "|    total_timesteps      | 1507328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137999775 |\n",
      "|    clip_fraction        | 0.0619       |\n",
      "|    clip_range           | 0.3          |\n",
      "|    entropy_loss         | -2.99        |\n",
      "|    explained_variance   | 0.0529       |\n",
      "|    learning_rate        | 0.000622     |\n",
      "|    loss                 | 1.21         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0185      |\n",
      "|    value_loss           | 12.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4478        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014876618 |\n",
      "|    clip_fraction        | 0.0734      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | 0.0712      |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.267      |\n",
      "|    n_updates            | 115         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    value_loss           | 6.48        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4475        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 366         |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019527702 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.92       |\n",
      "|    explained_variance   | 0.0105      |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | 0.0524      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4464        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 381         |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018426526 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | -0.0397     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.109      |\n",
      "|    n_updates            | 125         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4457        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 396         |\n",
      "|    total_timesteps      | 1769472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016754435 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | -0.121      |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.262      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 4.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4451        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 1835008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014385007 |\n",
      "|    clip_fraction        | 0.0704      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.0278      |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.276      |\n",
      "|    n_updates            | 135         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 9.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4441        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 427         |\n",
      "|    total_timesteps      | 1900544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015830342 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.064       |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.152      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 4.1         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 4432       |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 443        |\n",
      "|    total_timesteps      | 1966080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01808182 |\n",
      "|    clip_fraction        | 0.0946     |\n",
      "|    clip_range           | 0.3        |\n",
      "|    entropy_loss         | -2.95      |\n",
      "|    explained_variance   | -0.0567    |\n",
      "|    learning_rate        | 0.000622   |\n",
      "|    loss                 | -0.292     |\n",
      "|    n_updates            | 145        |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    value_loss           | 1.61       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4419        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 459         |\n",
      "|    total_timesteps      | 2031616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015253885 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | -0.00752    |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | 0.479       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 3.95        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training.\n",
    "model = PPO(MlpPolicy, env, verbose=3, gamma=0.95, n_steps=1024, ent_coef=0.0905168, learning_rate=0.00062211, vf_coef=0.042202, max_grad_norm=0.9, gae_lambda=0.99, n_epochs=10, clip_range=0.3, batch_size=256)\n",
    "model.learn(total_timesteps=2000000)\n",
    "model.save(policy_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of training\n",
    "### Reinstantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View our results\n",
    "# Reinstantiate.\n",
    "env = battlefield_vicuna.env(map_size=46, minimap_mode=False, step_reward=0.005,\n",
    "dead_penalty=-0.1, attack_penalty=-0.1, attack_opponent_reward=0.2,\n",
    "max_cycles=500, extra_features=False)\n",
    "env = ss.frame_stack_v1(env, 2)\n",
    "# Load policy\n",
    "model = PPO.load(policy_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gif generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array2gif import write_gif\n",
    "import numpy as np\n",
    "gif_name = policy_name + \".gif\"\n",
    "# Load policy\n",
    "model = PPO.load(policy_name)\n",
    "env = ss.frame_stack_v1(env, 2)\n",
    "env.reset()\n",
    "images=[]\n",
    "i = 0\n",
    "for agent in env.agent_iter():\n",
    "    obs, reward, done, info = env.last()\n",
    "    act = model.predict(obs, deterministic=True)[0] if not done else None\n",
    "    env.step(act)\n",
    "    i+=1\n",
    "    if i==100:\n",
    "        images.append(env.render(mode='rgb_array'))\n",
    "        i=0\n",
    "images = [i.transpose(1,0,2) for i in images]\n",
    "write_gif(images[:100], gif_name, fps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-in-one\n",
    "This cell contains all code explained above, to avoid having to run every cell each time. Moreover, it reloads the battlefield module each time, allowing modifications to environment between iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 18566  |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 7      |\n",
      "|    total_timesteps | 131072 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4318        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038323525 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | -2.27       |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.337      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 0.0313      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3457        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039577067 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | -0.161      |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.334      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.079      |\n",
      "|    value_loss           | 0.0163      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3166        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039106634 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | -0.108      |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.344      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0775     |\n",
      "|    value_loss           | 0.0133      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2981        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039338447 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | -0.104      |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.35       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0747     |\n",
      "|    value_loss           | 0.00961     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2867        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041329853 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | -0.086      |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.345      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0736     |\n",
      "|    value_loss           | 0.00658     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2807        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043509178 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | -0.0808     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.328      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0719     |\n",
      "|    value_loss           | 0.00453     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2773        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 378         |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046070635 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.51       |\n",
      "|    explained_variance   | -0.0521     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.33       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0706     |\n",
      "|    value_loss           | 0.003       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2737        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 430         |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047491804 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.47       |\n",
      "|    explained_variance   | -0.0322     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.325      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0692     |\n",
      "|    value_loss           | 0.00192     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2707        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 1310720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045083232 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.46       |\n",
      "|    explained_variance   | -0.0202     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0569     |\n",
      "|    value_loss           | 0.00125     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2673        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 539         |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046458155 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.43       |\n",
      "|    explained_variance   | -0.0189     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.287      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.059      |\n",
      "|    value_loss           | 0.000852    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2645        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 594         |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047681257 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.41       |\n",
      "|    explained_variance   | -0.0129     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.28       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.059      |\n",
      "|    value_loss           | 0.000571    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2619        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 650         |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048032254 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.4        |\n",
      "|    explained_variance   | -0.0259     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.286      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0553     |\n",
      "|    value_loss           | 0.000334    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2601       |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 705        |\n",
      "|    total_timesteps      | 1835008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04458905 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.3        |\n",
      "|    entropy_loss         | -2.41      |\n",
      "|    explained_variance   | -0.0193    |\n",
      "|    learning_rate        | 0.000622   |\n",
      "|    loss                 | -0.271     |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0497    |\n",
      "|    value_loss           | 0.000201   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2586        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 760         |\n",
      "|    total_timesteps      | 1966080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042397067 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.42       |\n",
      "|    explained_variance   | -0.0463     |\n",
      "|    learning_rate        | 0.000622    |\n",
      "|    loss                 | -0.286      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.046      |\n",
      "|    value_loss           | 0.000129    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2573       |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 814        |\n",
      "|    total_timesteps      | 2097152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03771838 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.3        |\n",
      "|    entropy_loss         | -2.43      |\n",
      "|    explained_variance   | -0.0284    |\n",
      "|    learning_rate        | 0.000622   |\n",
      "|    loss                 | -0.268     |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0414    |\n",
      "|    value_loss           | 0.000101   |\n",
      "----------------------------------------\n",
      "pygame 2.0.0 (SDL 2.0.12, python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import battlefield_vicuna\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3 import PPO\n",
    "import supersuit as ss\n",
    "from array2gif import write_gif\n",
    "import numpy as np\n",
    "import imp\n",
    "imp.reload(battlefield_vicuna)\n",
    "# Parallel version, death is possibly dangerous.\n",
    "policy_name = \"mediumpass9.2\"\n",
    "#Initial environment\n",
    "env = battlefield_vicuna.parallel_env(map_size=46, minimap_mode=False, step_reward=0.005,\n",
    "dead_penalty=-0.1, attack_penalty=-0.1, attack_opponent_reward=0.1,\n",
    "max_cycles=2000, extra_features=False)\n",
    "env.reset()\n",
    "#Stacking frames for movement #FRAMES ARE STACKED\n",
    "env = ss.frame_stack_v1(env, 2)\n",
    "# Handling the death of agents for vectorization\n",
    "env = ss.black_death_v2(env)\n",
    "#Vectorize the environment\n",
    "env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "##vectorize_aec_env_v0(aec_env, num_envs, num_cpus=0)\n",
    "#Start parallel training. n cpus, 2n environments.\n",
    "env = ss.concat_vec_envs_v1(env, 8, num_cpus=4, base_class='stable_baselines3')\n",
    "# Training\n",
    "model = PPO(MlpPolicy, env, verbose=3, gamma=0.95, n_steps=256, ent_coef=0.0905168, learning_rate=0.00062211, vf_coef=0.042202, max_grad_norm=0.9, gae_lambda=0.99, n_epochs=10, clip_range=0.3, batch_size=256)\n",
    "model.learn(total_timesteps=2000000)\n",
    "model.save(policy_name)\n",
    "# View our results\n",
    "# Reinstantiate.\n",
    "env = battlefield_vicuna.env(map_size=46, minimap_mode=False, step_reward=-0.005,\n",
    "dead_penalty=-0.1, attack_penalty=-0.1, attack_opponent_reward=1,\n",
    "max_cycles=500, extra_features=False)\n",
    "gif_name = policy_name + \".gif\"\n",
    "# Load policy\n",
    "model = PPO.load(policy_name)\n",
    "env = ss.frame_stack_v1(env, 2)\n",
    "env.reset()\n",
    "images=[]\n",
    "i = 0\n",
    "\n",
    "for agent in env.agent_iter():\n",
    "    obs, reward, done, info = env.last()\n",
    "    act = model.predict(obs, deterministic=True)[0] if not done else None\n",
    "    env.step(act)\n",
    "    i+=1\n",
    "    if i==100:\n",
    "        images.append(env.render(mode='rgb_array'))\n",
    "        i=0\n",
    "images = [i.transpose(1,0,2) for i in images]\n",
    "write_gif(images[:150], gif_name, fps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging\n",
    "For purposes of vizualization, here is useful code to render the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.0 (SDL 2.0.12, python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import battlefield_vicuna\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3 import PPO\n",
    "import supersuit as ss\n",
    "from matplotlib import pyplot as plt\n",
    "env = battlefield_vicuna.parallel_env(map_size=46, minimap_mode=False, step_reward=0.005,\n",
    "dead_penalty=-0.1, attack_penalty=-0.1, attack_opponent_reward=0.2,\n",
    "max_cycles=100, extra_features=False)\n",
    "env.reset();\n",
    "# Visualisation commands\n",
    "# Image\n",
    "image = env.render(mode='rgb_array')\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pygame rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.0 (SDL 2.0.12, python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import battlefield_vicuna\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3 import PPO\n",
    "import supersuit as ss\n",
    "env = battlefield_vicuna.env(map_size=46, minimap_mode=False, step_reward=0.005,\n",
    "dead_penalty=-0.1, attack_penalty=-0.1, attack_opponent_reward=0.2,\n",
    "max_cycles=500, wall=5, noise=0, extra_features=False)\n",
    "env = ss.frame_stack_v1(env, 2)\n",
    "# Load policy\n",
    "model = PPO.load(\"policytest\")\n",
    "env.reset()\n",
    "for agent in env.agent_iter():\n",
    "    obs, reward, done, info = env.last()\n",
    "    act = model.predict(obs, deterministic=True)[0] if not done else None\n",
    "    env.step(act)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gif rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parallel_env() got multiple values for argument 'wall'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-46492447404b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0marray2gif\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrite_gif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m env = battlefield_vicuna.env(map_size=46, minimap_mode=False, step_reward=0.005,\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdead_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_opponent_reward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m max_cycles=500, wall=1, noise=0, extra_features=False)\n",
      "\u001b[0;32m~/Documents/magent_env.py\u001b[0m in \u001b[0;36menv_fn\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0menv_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAssertOutOfBoundsWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrderEnforcingWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/battlefield_vicuna.py\u001b[0m in \u001b[0;36mraw_env\u001b[0;34m(map_size, max_cycles, minimap_mode, extra_features, **reward_args)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraw_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_map_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cycles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_cycles_default\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimap_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimap_mode_default\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mreward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_parallel_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cycles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimap_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mreward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: parallel_env() got multiple values for argument 'wall'"
     ]
    }
   ],
   "source": [
    "import battlefield_vicuna\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3 import PPO\n",
    "import supersuit as ss\n",
    "from array2gif import write_gif\n",
    "import numpy as np\n",
    "env = battlefield_vicuna.env(map_size=46, minimap_mode=False, step_reward=0.005,\n",
    "dead_penalty=-0.1, attack_penalty=-0.1, attack_opponent_reward=0.2,\n",
    "max_cycles=500, wall=1, noise=0, extra_features=False)\n",
    "env = ss.frame_stack_v1(env, 2)\n",
    "# Load policy\n",
    "model = PPO.load(\"policytest\")\n",
    "env.reset()\n",
    "images=[]\n",
    "i = 0\n",
    "for agent in env.agent_iter():\n",
    "    obs, reward, done, info = env.last()\n",
    "    act = model.predict(obs, deterministic=True)[0] if not done else None\n",
    "    env.step(act)\n",
    "    i+=1\n",
    "    if i==100:\n",
    "        images.append(env.render(mode='rgb_array'))\n",
    "        i=0\n",
    "images = [i.transpose(1,0,2) for i in images]\n",
    "write_gif(images[:100], 'new1.gif', fps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formations\n",
    "### For the battlefield_vicuna.py\n",
    "\n",
    "## Army formations\n",
    "These are code parts of the battlefield_(...).py that represents the implementation of the Battlefield environment. More specifically, here is the position of all agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Military formations, 32 agents per team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = 23\n",
    "# left\n",
    "pos = []\n",
    "for x in range(6, 9, 2):\n",
    "    for y in range(middle-8*2,middle+8*2, 2):\n",
    "        pos.append([x, y, 0])\n",
    "# right\n",
    "pos = []\n",
    "for x in range(2*middle-9, 2*middle-6, 2):\n",
    "    for y in range(middle-8*2,middle+8*2, 2):\n",
    "        pos.append([x, y, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wall Formations\n",
    "These are code parts of the battlefield_(...).py that represents the implementation of the Battlefield environment. More specifically, here is the position of all inner walls.\n",
    "### Torus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(21, 21),\n",
       " (22, 21),\n",
       " (23, 21),\n",
       " (24, 21),\n",
       " (21, 22),\n",
       " (22, 22),\n",
       " (23, 22),\n",
       " (24, 22),\n",
       " (21, 23),\n",
       " (22, 23),\n",
       " (23, 23),\n",
       " (24, 23),\n",
       " (21, 24),\n",
       " (22, 24),\n",
       " (23, 24),\n",
       " (24, 24)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = []\n",
    "wall = self.wall\n",
    "for y in range(middle-wall-1,middle+wall+1):\n",
    "    for x in range(middle-wall-1,middle+wall+1):\n",
    "        if random.random() >= self.noise:\n",
    "            pos.append((x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-torus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "wall = self.wall\n",
    "off = 10\n",
    "for y in range(middle-wall-1+off,middle+wall+1+off):\n",
    "    for x in range(middle-wall-1,middle+wall+1):\n",
    "        if random.random() >= self.noise:\n",
    "            pos.append((x, y))\n",
    "for y in range(middle-wall-1-off,middle+wall+1-off):\n",
    "    for x in range(middle-wall-1,middle+wall+1):\n",
    "        if random.random() >= self.noise:\n",
    "            pos.append((x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separation 2 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "wall = self.wall # 9 or 10\n",
    "off = 12\n",
    "for y in range(middle-wall-1+off,middle+wall+1+off):\n",
    "    for x in range(middle-wall-1,middle+wall+1):\n",
    "        if random.random() >= self.noise:\n",
    "            pos.append((x, y))\n",
    "for y in range(middle-wall-1-off,middle+wall+1-off):\n",
    "    for x in range(middle-wall-1,middle+wall+1):\n",
    "        if random.random() >= self.noise:\n",
    "            pos.append((x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperation 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "wall = self.wall # 9 or 10\n",
    "for y in range(0,20):\n",
    "    for x in range(15-wall-1,15+wall+1):\n",
    "        if random.random() >= self.noise:\n",
    "            pos.append((x, y))\n",
    "for y in range(26,46):\n",
    "    for x in range(15-wall-1,15+wall+1):\n",
    "        if random.random() >= self.noise:\n",
    "            pos.append((x, y))\n",
    "for y in range(0,20):\n",
    "    for x in range(30-wall-1,30+wall+1):\n",
    "        if random.random() >= self.noise:\n",
    "            pos.append((x, y))\n",
    "for y in range(26,46):\n",
    "    for x in range(30-wall-1,30+wall+1):\n",
    "        if random.random() >= self.noise:\n",
    "            pos.append((x, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
